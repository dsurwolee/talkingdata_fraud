{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_data_size(df):\n",
    "    \n",
    "    intcols = [c for c in df.columns if df[c].dtypes == 'int64']\n",
    "    \n",
    "    for c in intcols:\n",
    "        \n",
    "        mx = df[c].max()\n",
    "        \n",
    "        if mx < 255:\n",
    "            df[c] = df[c].astype(np.uint8)\n",
    "        elif mx < 65535:\n",
    "            df[c] = df[c].astype(np.uint16)\n",
    "        elif mx < 4294967295:\n",
    "            df[c] = df[c].astype(np.uint32)\n",
    "        \n",
    "def top_k_categorical(df, feats, k, target):\n",
    "\n",
    "    df = df.copy()\n",
    "    top_k_feat = {}\n",
    "    for feat in feats:\n",
    "        top_k_values = (\n",
    "                df.loc[df[target] == 1, feat]\n",
    "                    .value_counts()[:k]\n",
    "                    .index\n",
    "        )\n",
    "        top_k_feat[feat] = top_k_values\n",
    "        df.loc[~df[feat].isin(top_k_values), feat] = 'other'\n",
    "\n",
    "    dummy_df = pd.get_dummies(df[feats])\n",
    "    return dummy_df, top_k_feat\n",
    "\n",
    "def top_k_categorical_test(df, feats_dict):\n",
    "    \n",
    "    df = df.copy()\n",
    "    for k, v in feats_dict.items():\n",
    "        df.loc[~df[k].isin(v),k] = 'other'\n",
    "        \n",
    "    dummy_df = pd.get_dummies(df[list(feats_dict.keys())])\n",
    "    return dummy_df\n",
    "\n",
    "def create_ip_profile(df, key):\n",
    "    df['ip_event_number'] = df.groupby(key).cumcount()\n",
    "    df['ip_event_count'] = df.groupby(key).transform('count')\n",
    "    return df \n",
    "\n",
    "def create_ts_dummy(df, col):\n",
    "    df = pd.to_datetime(df[col]).reset_index()\n",
    "    df['hour'] = df[col].dt.hour\n",
    "    df['minute'] = df[col].dt.minute\n",
    "    df['seconds'] = df[col].dt.second\n",
    "    df.drop(['index', col],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Filepath to raw data\n",
    "datapath = '/Users/daniellee/Desktop/Data/Datasets/talkingdata_fraud/'\n",
    "\n",
    "## Load data \n",
    "cols = ['app','device','os','channel','is_attributed']\n",
    "train = pd.read_csv(datapath+'train.csv', usecols=cols)\n",
    "test = pd.read_csv(datapath+'test.csv', usecols=cols[:-1])    \n",
    "\n",
    "## Get dummy data\n",
    "dummy_train, feats_dict = top_k_categorical(train, cols[:-1], 10, 'is_attributed')\n",
    "del train \n",
    "\n",
    "dummy_test = top_k_categorical_test(test, feats_dict)\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_profile_raw, test_profile_raw = (\n",
    "                            [pd.read_csv(datapath+'{}.csv'.format(n), usecols=['ip']) \n",
    "                               for n in ['train','test']]\n",
    ")\n",
    "\n",
    "train_profile, test_profile = (\n",
    "                    [create_ip_profile(df, 'ip') \n",
    "                     for df in [train_profile_raw, test_profile_raw]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ts_raw, test_ts_raw = (\n",
    "                            [pd.read_csv(datapath+'{}.csv'.format(n), usecols=['click_time']) \n",
    "                               for n in ['train','test']]\n",
    ")\n",
    "\n",
    "train_ts, test_ts = (\n",
    "                    [create_ts_dummy(df, 'click_time') \n",
    "                     for df in [train_ts_raw, test_ts_raw]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train = pd.concat([dummy_train, train_profile, train_ts], axis=1)\n",
    "new_test = pd.concat([dummy_test, test_profile, test_ts], axis=1)\n",
    "\n",
    "reduce_data_size(new_train)\n",
    "reduce_data_size(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_hdf(datapath+'m3_features/my_filename.hdf','mydata',mode='w')\n",
    "new_test.to_pickle(datapath+'m3_features/m3_categorical_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
