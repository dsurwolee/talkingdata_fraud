{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_data_size(df):\n",
    "    \n",
    "    intcols = [c for c in df.columns if df[c].dtypes == 'int64']\n",
    "    \n",
    "    for c in intcols:\n",
    "        \n",
    "        mx = df[c].max()\n",
    "        \n",
    "        if mx < 255:\n",
    "            df[c] = df[c].astype(np.uint8)\n",
    "        elif mx < 65535:\n",
    "            df[c] = df[c].astype(np.uint16)\n",
    "        elif mx < 4294967295:\n",
    "            df[c] = df[c].astype(np.uint32)\n",
    "        \n",
    "def top_k_categorical(df, feats, k, target):\n",
    "\n",
    "    df = df.copy()\n",
    "    top_k_feat = {}\n",
    "    for feat in feats:\n",
    "        top_k_values = (\n",
    "                df.loc[df[target] == 1, feat]\n",
    "                    .value_counts()[:k]\n",
    "                    .index\n",
    "        )\n",
    "        top_k_feat[feat] = top_k_values\n",
    "        df.loc[~df[feat].isin(top_k_values), feat] = 'other'\n",
    "\n",
    "    dummy_df = pd.get_dummies(df[feats])\n",
    "    return dummy_df, top_k_feat\n",
    "\n",
    "def top_k_categorical_test(df, feats_dict):\n",
    "    \n",
    "    df = df.copy()\n",
    "    for k, v in feats_dict.items():\n",
    "        df.loc[~df[k].isin(v),k] = 'other'\n",
    "        \n",
    "    dummy_df = pd.get_dummies(df[list(feats_dict.keys())])\n",
    "    return dummy_df\n",
    "\n",
    "def create_ip_profile(df, key):\n",
    "    df['ip_event_number'] = df.groupby(key).cumcount()\n",
    "    df['ip_event_count'] = df.groupby(key).transform('count')\n",
    "    return df \n",
    "\n",
    "def create_ts_dummy(df, col):\n",
    "    df = pd.to_datetime(df[col]).reset_index()\n",
    "    df['hour'] = df[col].dt.hour\n",
    "    df['minute'] = df[col].dt.minute\n",
    "    df['seconds'] = df[col].dt.second\n",
    "    df.drop(['index', col],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Filepath to raw data\n",
    "datapath = '/Users/daniellee/Desktop/Data/Datasets/talkingdata_fraud/'\n",
    "\n",
    "## Load data \n",
    "cols = ['app','device','os','channel','is_attributed']\n",
    "train = pd.read_csv(datapath+'train.csv', usecols=cols, nrows=10000000)\n",
    "test = pd.read_csv(datapath+'test.csv', usecols=cols[:-1], nrows=10000000)    \n",
    "\n",
    "## Get dummy data\n",
    "dummy_train, feats_dict = top_k_categorical(train, cols[:-1], 10, 'is_attributed')\n",
    "del train \n",
    "\n",
    "dummy_test = top_k_categorical_test(test, feats_dict)\n",
    "del test\n",
    "\n",
    "# Reduce size and pickle data\n",
    "# reduce_data_size(dummy_train)\n",
    "# reduce_data_size(dummy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_profile_raw, test_profile_raw = (\n",
    "                            [pd.read_csv(datapath+'{}.csv'.format(n), usecols=['ip'], nrows=10000000) \n",
    "                               for n in ['train','test']]\n",
    ")\n",
    "\n",
    "train_profile, test_profile = (\n",
    "                    [create_ip_profile(df, 'ip') \n",
    "                     for df in [train_profile_raw, test_profile_raw]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ts_raw, test_ts_raw = (\n",
    "                            [pd.read_csv(datapath+'{}.csv'.format(n), usecols=['click_time'], nrows=10000000) \n",
    "                               for n in ['train','test']]\n",
    ")\n",
    "\n",
    "train_ts, test_ts = (\n",
    "                    [create_ts_dummy(df, 'click_time') \n",
    "                     for df in [train_ts_raw, test_ts_raw]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-575392fcfbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdummy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_profile_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_profile_raw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreduce_data_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mreduce_data_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4ecb511759e5>\u001b[0m in \u001b[0;36mreduce_data_size\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreduce_data_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mintcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4ecb511759e5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreduce_data_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mintcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    954\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "new_train = pd.concat([dummy_train, train_profile_raw, train_profile_raw], axis=1)\n",
    "new_test = pd.concat([dummy_test, test_profile_raw, test_profile_raw], axis=1)\n",
    "\n",
    "reduce_data_size(new_train)\n",
    "reduce_data_size(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_pickle(datapath+'m3_categorical_train')\n",
    "new_test.to_pickle(datapath+'m3_categorical_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
